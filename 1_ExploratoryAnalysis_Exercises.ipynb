{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome\n",
    "\n",
    "## Overview\n",
    "During this session, you will walk through the work required to define a data science project and some recommendations for the initial approach to data. \n",
    "\n",
    "\n",
    "The goal is to perform Exploratory Data Analysis (EDA). First, you will need to help to define the project and perform data auditing. The EDA in this section will be enough for you to determine if you can accomplish the project with the information provided.\n",
    "<img src='./Images/HomeScreen.png' style=\"width:150px;\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pedometer App\n",
    "As a new Data Scientist in the Data Science Team you have been asked to improve a pedometer app. The app's ultimate goal is to drive the user to a healthier lifestyle.\n",
    "\n",
    "After downloading and testing the app, you notice that you need to start the recording manually, and that the only output to the user is the time and distance traveled.\n",
    "\n",
    "Then you meet with the development team who tells you that they extract over 500 different features for you to use from the accelerometer and gyroscope information. They believe that *more data is better*.\n",
    "\n",
    "\n",
    "<img src='./Images/TrackScreen.png' style=\"width:150px;\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Definition\n",
    "Narrow down into actionable items the following goal: *Drive the user to a healthier lifestyle*.\n",
    "\n",
    "Assume you have several formal and informal conversations with the stakeholders. After a lot of ideas and examples, you finally agree that you will enhance the activity tracker by providing the user with notifications and a dashboard summary showing the time spent being active and passive, resulting in suggestions to improve their lifestyle. Thus, you agree that the app will automatically record the following activities:\n",
    "    - Active:\n",
    "        - Walking\n",
    "        - Walking upstairs\n",
    "        - Walking downstairs\n",
    "        - Running\n",
    "        - Cycling\n",
    "    - Resting\n",
    "        - Sitting\n",
    "        - Laying while awake\n",
    "        - Laying while sleeping\n",
    "        - Standing\n",
    "        - Driving\n",
    "        \n",
    "<img src='./Images/DashboardIdea.png' style=\"width:150px;\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tackling the problem\n",
    "Move from a simple app that only gives the time and distance to an app that does Human Activity Recognition. Fragment this goal into small actionable items and iterate them, so you can rectify assumptions and include unexpected challenges.\n",
    "\n",
    "You must:\n",
    "- Record continuously by updating the app so it no longer requires activation.\n",
    "- Verify the prediction of active and resting activities given the available information.\n",
    "- Iterate the information recorded by the app and the verification to allow said predictions.\n",
    "- Integrate the prediction algorithm into the app.\n",
    "- Display activity trends in an engaging way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assesment and evaluation\n",
    "\n",
    "Good data scientists adhere to the garbage in, garbage out view of the world.\n",
    "\n",
    "The data assessment and evaluation is a crucial stage for any Data Science project. During this stage you will verify:\n",
    "- Data availability\n",
    "- Data completion\n",
    "- Data processing requirements\n",
    "- Data usefulness\n",
    "\n",
    "As you start to verify the prediction of resting and active activities given the available information, you have already started to do such verifications.\n",
    "\n",
    "After another round of meetings, you gain access to a data set of an experiment the developers performed. That experiment involved 30 people (subjects), performing 6 activities (Walking, Walking upstairs, Walking downstairs, Sitting, Standing, and Lying). The features in this experiment are the result of data transformations on the gyroscope and accelerometer output.\n",
    "\n",
    "With this data set you know that you won't be able to predict:\n",
    "- Running\n",
    "- Cycling\n",
    "- Lying while sleeping\n",
    "- Driving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import collections\n",
    "import os, requests, zipfile, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint as pp\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import eda_functions\n",
    "from IPython.display import Image\n",
    "\n",
    "if not os.path.isdir('./Data/UCI HAR Dataset/'):\n",
    "    HAR_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip'\n",
    "    req = requests.get(HAR_URL)\n",
    "    compressed = zipfile.ZipFile(io.BytesIO(req.content))\n",
    "    compressed.extractall('./Data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm the provided information (Audit)\n",
    "\n",
    "\n",
    "The data was manipulated, which may lead to several errors. These errors might be present in the form of:\n",
    "- Misclassification (e.g. of the activities, the subjects, or the data)\n",
    "- Incompleteness\n",
    "- Incoherence (e.g. date format “YYYY-mm-DD HH:MM:SS” where “SS” (seconds) is over 60)\n",
    "- Errors in using statistics (e.g. like the mean or in other transformations)\n",
    "\n",
    "Due to:\n",
    "- Dataset versioning (e.g. we’ve been provided with outdated information)\n",
    "- Language and terminology discrepancies\n",
    "- Undocumented manipulations\n",
    "- Data format mismatch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore within the files, folder structure and content\n",
    "Take a look at the directories to see what is happening. Use `os.listdir(<directory>)` to see what is in the recently created “UCI HAR Dataset” directory.\n",
    "\n",
    "Use the `pprint` or `print` functions to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('UCI HAR Dataset')\n",
    "print(os.listdir('./Data/UCI HAR Dataset/'))\n",
    "print('TRAIN FOLDER')\n",
    "print(os.listdir('./Data/UCI HAR Dataset/train'))\n",
    "print('TEST FOLDER')\n",
    "print(os.listdir('./Data/UCI HAR Dataset/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test folders\n",
    "\n",
    "Currently, you have:\n",
    "- 4 different text files in the beginning, which seem to be data dictionaries/labels for the internal datasets.\n",
    "- 2 folders with similar content: Test and Train.\n",
    "    - Inside the folders, you see two .txt files: X and Y. X is used to describe the independent variables and Y is the dependent variable, which is the objective function; in other words, the activity categorization for each combination of X’s variables.\n",
    "    \n",
    "Why would **Test** and **Train** have the same structure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm the provided information (Audit part 2)\n",
    "\n",
    "Remember that the data was manipulated which might lead to several errors. Look at the number of subjects, features, and activities to confirm they are what you’ve been told, and see where the difference come from otherwise. \n",
    "\n",
    "### Load the data\n",
    "\n",
    "After exploring the file and folder structure, load the data for its consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load activities and set them to their meanings\n",
    "activity_label = {int(key): value for key, value in eda_functions.get_key_value_pairs('./Data/UCI HAR Dataset/activity_labels.txt')}\n",
    "activities = pd.read_table('./Data/UCI HAR Dataset/train/y_train.txt', header=None, delim_whitespace=True)\n",
    "activities.columns = ['activity']\n",
    "activities = activities.replace({'activity':activity_label})\n",
    "\n",
    "#load subjects\n",
    "subjects = [int(line.strip()) for line in open('./Data/UCI HAR Dataset/train/subject_train.txt','r')]\n",
    "\n",
    "#load the feature names\n",
    "features = np.array([line.strip().split(' ')[1] for line in open('./Data/UCI HAR Dataset/features.txt', 'r')])\n",
    "\n",
    "#load the observations\n",
    "observations= pd.read_table('./Data/UCI HAR Dataset/train/X_train.txt', header=None, delim_whitespace=True, names=features)\n",
    "observations['subject'] = subjects\n",
    "observations['activities'] = activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief look at the data\n",
    "Now execute simple commands to get the counts and a very summarized view of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections.Counter(activities.activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collections.Counter(subjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predictors/features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(features.size)\n",
    "print(features[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(observations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### size and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(observations.shape)\n",
    "print(features.size)\n",
    "print(len(subjects))\n",
    "print(activities.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics review\n",
    "For this section, **only** look at the **Train** data, as this is the set for the modeling.\n",
    "\n",
    "**Note:** Remember that the test data is for model validation.\n",
    "\n",
    "\n",
    "\n",
    "## Tendency measures\n",
    "To gather data about percentiles and central tendency use `observations.shape`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This dataset has all the features (561 in the features file), and all the observations (7352 corresponding to the number of rows in the activity dataset).\n",
    "\n",
    "Use `observations.describe()` to obtain the basic measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can confirm two important things:\n",
    "- You are aggregating already aggregated columns (e.g. you are looking at means of means).\n",
    "- You have too much data and there does not seem to be something evidently useful.\n",
    "\n",
    "By comparing for example at the `tBodyAcc-mean()-Z` and `tBodyAcc-max()-Z` you can see that there is a measure of more variation and a wider range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots and Histograms\n",
    "\n",
    "Since **activities** is what you are trying to predict and understand, see how much representation for each of them is in the dataset, as it may affect the model if there is too much bias.\n",
    "\n",
    "### Barplots\n",
    "Create a barplot with the count of occurrences for each activity. The easiest way to solve this is by calling the activity column with `activities.activity`, applying `.value_counts()` and plotting with `.plot(kind='bar')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(activities.activity.value_counts())\n",
    "activities.activity.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make the same for the `subjects` data (which is a list).\n",
    "\n",
    "Keep in mind that `value_counts` only works with Pandas series. Use `pd.Series(subjects)` to convert it into that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "Reduce the dataset to the total body acceleration columns, since they are the ones having differences in their distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimated = 'tBodyAcc'\n",
    "meanfeatures = np.array([feature for feature in features if estimated in feature ])\n",
    "meanfeatures = np.append(meanfeatures,['activities','subject'])\n",
    "observed_feature = observations[meanfeatures]\n",
    "subsetuser = observed_feature[observed_feature['subject']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have plotted a histogram with the mean total body acceleration on the **Z** axis for all our subjects. Remember, it is expected for it it to have a variation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = 'tBodyAcc-mean()-Z'\n",
    "mean_series_to_plot = observed_feature[feature]\n",
    "eda_functions.hist_plot(mean_series_to_plot, feature, 100, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now replicate the code for the maximum total body acceleration `tBodyAcc-max()-Z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = 'tBodyAcc-max()-Z'\n",
    "max_series_to_plot = observed_feature[feature]\n",
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, take a look at only one subject so that you can understand with one example what is going on. For this, use the `subsetuser` dataframe, which containes only the first subject (i.e. `observed_feature[observed_feature['subject']==1]`), and replicate the previous code; first with the mean then with the max values.\n",
    "\n",
    "**Note:** to change the subject go to the code cell right below the histogram subtitle and change the number id in the corresponding line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = 'tBodyAcc-mean()-Z'\n",
    "user_mean_series_to_plot = subsetuser[feature]\n",
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, you can see that the mean differs, so there is variability between people.\n",
    "\n",
    "You could argue that this may be because someone spent a longer time doing one activity rather than another. To test this, let’s use the `tBodyAcc-max()-Z` and look at when the subject is walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature = 'tBodyAcc-max()-Z'\n",
    "walking_user_max_series_to_plot = subsetuser.loc[subsetuser['activities']=='WALKING',feature]\n",
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see what happens when he is sitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "feature = 'tBodyAcc-max()-Z'\n",
    "sitting_user_max_series_to_plot = subsetuser.loc[subsetuser['activities']=='SITTING',feature]\n",
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know that there is variability.\n",
    "- **Activity variability:** There seem to be some features that will give information to identify each activity.\n",
    "- **User variability:** This seems to introduce some noise. Since, as a Data Scientist, you should go from simple to more elaborate solutions, you will now only look at one user for our analysis until you are satisfied this has been enough.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you start talking about its implementation, you may be implying that you want to create one model per user instead of generalizing how any human being may perform each activity (In this scenario, the arrival of a new user, for whom there is no information to build their model). This is formally known as the **cold start** problem.\n",
    "\n",
    "\n",
    "For now, don’t worry about that problem. You are still understanding the data and its behaviors and you are not sure we can generate something out of it. Keep it simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles and boxplots\n",
    "\n",
    "Look from a different view the same data and you might get a better idea of what is the main identifier.\n",
    "\n",
    "Boxplots are another way to visualize a variable’s distribution, making really evident the interquartile range, the presence of outliers, and the median.\n",
    "\n",
    "The mean total body acceleration for the **Z** axis is already plotted for you to see.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.boxplot(observed_feature['tBodyAcc-mean()-Z'], showfliers=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Replicate the code for the maximum values on axis **Z** (`tBodyAcc-max()-Z`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplot\n",
    "\n",
    "So far, you have looked at one-dimensional analysis, and this has already shed interesting insights into the data. Nevertheless, you have plenty of data and you want to see their interactions. A scatterplot is a bidimensional tool and is useful for understanding correlations and data capacity, among other things.\n",
    "\n",
    "Since you have a lot of data, instead of plotting one combination of values, you can use the `scatter_matrix` function from the `Pandas` plotting tools. This is useful because it gives you the density plot in the diagonal. All you need to know about it is that it is some sort of histogram smoothing.\n",
    "\n",
    "**Note:** In reality it to obtain this diagonal the code performs a *kernel density estimation*, which starts making inferences about the data which we do not want to formalize during the exploratory data analysis, so it will not be delved into.\n",
    "\n",
    "\n",
    "The `scatter_matrix_plot()` simplifies the plotting of all 3 axes of any variable. Use it to look at the the static activities' scatter plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eda_functions.scattermatrixplot(subsetuser,'activities',['SITTING','STANDING','LAYING'],'tBodyAcc-max()')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no evident correlation in the total body acceleration for the *static activities* since the person is not moving. You may explain the outliers or most of the changes with the breathing movement or other sources of *noise*.\n",
    "\n",
    "Now plot the dynamic activities 'WALKING', 'WALKING_UPSTAIRS' and 'WALKING_DOWNSTAIRS' to compare and contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may play more with the data and scatterplot you desire to generate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "What the developers described is data that might be useful in creating a dashboard. You found that some features in the data might help classify both active and resting activities.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
